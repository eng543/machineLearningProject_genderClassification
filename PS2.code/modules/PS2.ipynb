{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from node import Node\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'is_nominal': True, 'name': 'winner'}, {'is_nominal': False, 'name': 'winpercent'}, {'is_nominal': False, 'name': 'oppwinningpercent'}, {'is_nominal': True, 'name': 'weather'}, {'is_nominal': False, 'name': 'temperature'}, {'is_nominal': False, 'name': 'numinjured'}, {'is_nominal': False, 'name': 'oppnuminjured'}, {'is_nominal': True, 'name': 'startingpitcher'}, {'is_nominal': True, 'name': 'oppstartingpitcher'}, {'is_nominal': False, 'name': 'dayssincegame'}, {'is_nominal': False, 'name': 'oppdayssincegame'}, {'is_nominal': True, 'name': 'homeaway'}, {'is_nominal': False, 'name': 'rundifferential'}, {'is_nominal': False, 'name': 'opprundifferential'}]\n"
     ]
    }
   ],
   "source": [
    "import csv, collections\n",
    "\n",
    "# Note: nominal data are integers while numeric data consists of floats\n",
    "def parse(filename, keep_unlabeled):\n",
    "    '''\n",
    "    takes a filename and returns attribute information and all the data in array of arrays\n",
    "    This function also rotates the data so that the 0 index is the winner attribute, and returns\n",
    "    corresponding attribute metadata\n",
    "    '''\n",
    "    # initialize variables\n",
    "    array = []\n",
    "    csvfile = open(filename,'rb')\n",
    "    fileToRead = csv.reader(csvfile, delimiter=' ',quotechar=',')\n",
    "\n",
    "    # skip first line of data\n",
    "    fileToRead.next()\n",
    "\n",
    "    # set attributes\n",
    "    attributes = [\n",
    "    {\n",
    "        'name': \"winpercent\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"oppwinningpercent\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"weather\",\n",
    "        'is_nominal': True\n",
    "    },\n",
    "    {\n",
    "        'name': \"temperature\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"numinjured\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"oppnuminjured\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"startingpitcher\",\n",
    "        'is_nominal': True\n",
    "    },\n",
    "    {\n",
    "        'name': \"oppstartingpitcher\",\n",
    "        'is_nominal': True\n",
    "    },\n",
    "    {\n",
    "        'name': \"dayssincegame\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"oppdayssincegame\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"homeaway\",\n",
    "        'is_nominal': True\n",
    "    },\n",
    "    {\n",
    "        'name': \"rundifferential\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"opprundifferential\",\n",
    "        'is_nominal': False\n",
    "    },\n",
    "    {\n",
    "        'name': \"winner\",\n",
    "        'is_nominal': True\n",
    "    }]\n",
    "\n",
    "    # iterate through rows of actual data\n",
    "    for row in fileToRead:\n",
    "        # change each line of data into an array\n",
    "        temp =row[0].split(',')\n",
    "        if (not keep_unlabeled) and (temp[len(attributes) - 1] == \"?\"):\n",
    "            continue\n",
    "        for i in range(len(temp)):\n",
    "            # data preprocessing\n",
    "            if temp[i] == '?':\n",
    "                temp[i] = None\n",
    "            elif attributes[i]['is_nominal']:\n",
    "                temp[i] = int(temp[i])\n",
    "            else:\n",
    "                temp[i] = float(temp[i])\n",
    "\n",
    "        # rotate data so that the target attribute is at index 0\n",
    "        d = collections.deque(temp)\n",
    "        d.rotate(1)\n",
    "        array.append(list(d))\n",
    "\n",
    "    array.pop()\n",
    "\n",
    "    # rotate attributes so that it corresponds to the data\n",
    "    attributes = collections.deque(attributes)\n",
    "    attributes.rotate(1)\n",
    "    attributes = list(attributes)\n",
    "\n",
    "\n",
    "    return array, attributes\n",
    "\n",
    "data = parse(\"../data/test_btrain.csv\", True)[0]\n",
    "\n",
    "attributes = parse(\"../data/test_btrain.csv\", True)[1]\n",
    "\n",
    "print attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTE: you don't need to change anything in this function\n",
    "import pickle\n",
    "\n",
    "def makePickle(obj, filename):\n",
    "  f = open(filename, \"wb\")\n",
    "  p = pickle.Pickler(f)\n",
    "  p.dump(obj)\n",
    "  f.close()\n",
    "\n",
    "def loadPickle(filename):\n",
    "\tf = open(filename, \"rb\")\n",
    "\tu = pickle.Unpickler(f)\n",
    "\tret = u.load()\n",
    "\tf.close()\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_homogenous(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Checks if the attribute at index 0 is the same for the data_set, if so return output otherwise None.\n",
    "    ========================================================================================================\n",
    "    Output: Return either the homogenous attribute or None\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    # if homogeneous, means that the tree is finished\n",
    "    outcomes = [] #Nathan - moved this bit here\n",
    "    for i in range(0, len(data_set)):\n",
    "        outcomes.append([data_set[i][0]])\n",
    "        \n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "\n",
    "    for i in range(0, len(outcomes)):\n",
    "        if outcomes[i] == [1]:\n",
    "            positive_count += 1\n",
    "        else:\n",
    "            negative_count += 1\n",
    "            \n",
    "    if (positive_count != 0) and (negative_count != 0):\n",
    "        return None\n",
    "    else:\n",
    "        if positive_count != 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# ======== Test Cases =============================\n",
    "#data_set = [[0],[1],[1],[1],[1],[1]]\n",
    "#print check_homogenous(data_set) ==  None\n",
    "#data_set = [[0],[1],[None],[0]]\n",
    "#print check_homogenous(data_set) ==  None\n",
    "#data_set = [[1],[1],[1],[1],[1],[1]]\n",
    "#print check_homogenous(data_set) ==  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Takes a data_set and finds mode of index 0.\n",
    "    ========================================================================================================\n",
    "    Output: mode of index 0.\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    outcomes = [] #Nathan - added this bit for simplicity\n",
    "    for i in range(0, len(data_set)):\n",
    "        outcomes.append([data_set[i][0]])\n",
    "        \n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for i in range(0, len(outcomes)):\n",
    "        if outcomes[i] == [1]:\n",
    "            positive_count += 1\n",
    "        else:\n",
    "            negative_count += 1\n",
    "\n",
    "    if positive_count > negative_count:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# ======== Test case =============================\n",
    "#data_set = [[0],[1],[1],[1],[1],[1]]\n",
    "#print mode(data_set) == 1\n",
    "#data_set = [[0],[1],[0],[0]]\n",
    "#print mode(data_set) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Calculates the entropy of the attribute at the 0th index, the value we want to predict.\n",
    "    ========================================================================================================\n",
    "    Output: Returns entropy. See Textbook for formula\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    #### this should get fed a list of lists with the outcome labels for the subset of data relevant for the feature\n",
    "\n",
    "    # commented out code creates this list of lists if the input happens to be the entire data_set\n",
    "    #outcomes = []\n",
    "    #for i in range(0, len(data_set)):\n",
    "    #    outcomes.append([data_set[i][0]])\n",
    "\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for i in range(0, len(data_set)):\n",
    "        if data_set[i] == [1]:\n",
    "            positive_count += 1\n",
    "        else:\n",
    "            negative_count += 1\n",
    "\n",
    "    if positive_count != 0 and negative_count != 0:\n",
    "        total = float(positive_count + negative_count)\n",
    "        p_positive = positive_count/total\n",
    "        p_negative = negative_count/total\n",
    "\n",
    "        log_positive = math.log(p_positive, 2)\n",
    "        log_negative = math.log(p_negative, 2)\n",
    "\n",
    "        entropy_calculation = - ((p_positive * log_positive) + (p_negative * log_negative))\n",
    "\n",
    "        return entropy_calculation\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# ======== Test case =============================\n",
    "# data_set = [[0],[1],[1],[1],[0],[1],[1],[1]]\n",
    "# entropy(data_set) == 0.811\n",
    "# data_set = [[0],[0],[1],[1],[0],[1],[1],[0]]\n",
    "# entropy(data_set) == 1.0\n",
    "# data_set = [[0],[0],[0],[0],[0],[0],[0],[0]]\n",
    "# entropy(data_set) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hits(data_set):\n",
    "    '''\n",
    "    Create dictionary with tally of number of positive and negative examples.\n",
    "    ERIN: MIGHT BE GOOD TO USE THIS WITHIN OTHER FUNCTION RATHER THAN INCREMENTING IN VARIABLES EACH TIME\n",
    "    '''\n",
    "    hits = {}\n",
    "\n",
    "    for i in range(len(data_set)):\n",
    "        if data_set[i][0] in hits:\n",
    "            hits[data_set[i][0]] += 1\n",
    "        else:\n",
    "            hits[data_set[i][0]] = 1\n",
    "\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gain_ratio_nominal(data_set, attribute):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data_set, index for a nominal attribute\n",
    "    ========================================================================================================\n",
    "    Job:    Finds the gain ratio of a nominal attribute in relation to the variable we are training on.\n",
    "    ========================================================================================================\n",
    "    Output: Returns gain_ratio. See https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    freqs = get_hits(data_set)\n",
    "    total_examples = freqs[0] + freqs[1]\n",
    "\n",
    "    ent_data_set = []\n",
    "\n",
    "    for i in range(0, len(data_set)):\n",
    "        ent_data_set.append([data_set[i][0]])\n",
    "\n",
    "    total_entropy = entropy(ent_data_set)\n",
    "\n",
    "    # dict of attribute values and relevant examples\n",
    "    nom_dict = split_on_nominal(data_set, attribute)\n",
    "\n",
    "\n",
    "    subset_entropy = 0\n",
    "    intrinsic_value = 0\n",
    "\n",
    "    for value in nom_dict.keys():\n",
    "        # information gain\n",
    "        num_value = len(nom_dict[value])\n",
    "        prob_value = num_value/float(total_examples)\n",
    "\n",
    "        rel_ent_data_set = []\n",
    "\n",
    "        for i in range(0, len(nom_dict[value])):\n",
    "            rel_ent_data_set.append([nom_dict[value][i][0]])\n",
    "\n",
    "        relative_entropy = entropy(rel_ent_data_set)\n",
    "\n",
    "        subset_entropy += prob_value * relative_entropy\n",
    "\n",
    "        # intrinsic value\n",
    "        intrinsic_value += - prob_value * math.log(prob_value, 2)\n",
    "    if intrinsic_value == 0:\n",
    "        ratio = 0\n",
    "    else:\n",
    "        ratio = (total_entropy - subset_entropy)/intrinsic_value\n",
    "        \n",
    "    if ratio < 0.0001: #Nathan: epsilon\n",
    "        return 0\n",
    "    else:\n",
    "        return ratio\n",
    "\n",
    "# ======== Test case =============================\n",
    "#data_set, attr = [[1, 2], [1, 0], [1, 0], [0, 2], [0, 2], [0, 0], [1, 3], [0, 4], [0, 3], [1, 1]], 1\n",
    "#print gain_ratio_nominal(data_set,attr) == 0.11470666361703151\n",
    "#data_set, attr = [[1, 2], [1, 2], [0, 4], [0, 0], [0, 1], [0, 3], [0, 0], [0, 0], [0, 4], [0, 2]], 1\n",
    "#print gain_ratio_nominal(data_set,attr) == 0.2056423328155741\n",
    "#data_set, attr = [[0, 3], [0, 3], [0, 3], [0, 4], [0, 4], [0, 4], [0, 0], [0, 2], [1, 4], [0, 4]], 1\n",
    "#print gain_ratio_nominal(data_set,attr) == 0.06409559743967516\n",
    "\n",
    "#data_set, attr = [[0, 3, 0], [0, 3, 1], [0, 3, 1], [0, 4, 2], [0, 4, 2], [0, 4, 3], [0, 0, 0], [0, 2, 1], [1, 4, 2], [0, 4, 2]], 2\n",
    "#print gain_ratio_nominal(data_set,attr) \n",
    "\n",
    "#data_set, attr = [[0, 3, 0], [0, 3, 0], [0, 3, 0], [0, 4, 0], [0, 4, 0], [0, 4, 0], [0, 0, 0], [0, 2, 0], [1, 4, 1], [0, 4, 0]], 2\n",
    "#print gain_ratio_nominal(data_set,attr) #== 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gain_ratio_numeric(data_set, attribute, steps):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data set, the index for a numeric attribute, and a step size for normalizing the data.\n",
    "    ========================================================================================================\n",
    "    Job:    Calculate the gain_ratio_numeric and find the best single threshold value\n",
    "            The threshold will be used to split examples into two sets\n",
    "                 those with attribute value GREATER THAN OR EQUAL TO threshold\n",
    "                 those with attribute value LESS THAN threshold\n",
    "            Use the equation here: https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "            And restrict your search for possible thresholds to examples with array index mod(step) == 0\n",
    "    ========================================================================================================\n",
    "    Output: This function returns the gain ratio and threshold value\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    # max gain_ratio among all possible splits\n",
    "    # steps = how many times do you calculate the gain_ratio\n",
    "    # threshold = splitting_value\n",
    "\n",
    "    freqs = get_hits(data_set)\n",
    "    total_examples = freqs[0] + freqs[1]\n",
    "\n",
    "    ent_data_set = []\n",
    "\n",
    "    for i in range(0, len(data_set)):\n",
    "        ent_data_set.append([data_set[i][0]])\n",
    "\n",
    "    total_entropy = entropy(ent_data_set)\n",
    "\n",
    "    step_indices = []\n",
    "    k = 0\n",
    "    if steps < len(data_set):\n",
    "        while k < len(data_set):\n",
    "            step_indices.append(k)\n",
    "            k += steps\n",
    "    else:\n",
    "        print(\"boohoo we failed\")\n",
    "    ratios = {}\n",
    "\n",
    "    for step in step_indices:\n",
    "        temp_split_value = data_set[step][attribute] #Nathan: data_set[step][1] -> data_set[step][attribute]\n",
    "\n",
    "        # anything less than split value is in list at 0th index, greater than equal to in 1th index\n",
    "        subset_split = [[],[]]\n",
    "        for i in range(0, len(data_set)):\n",
    "            #print data_set[i][1], data_set[i][attribute]\n",
    "            if data_set[i][attribute] < temp_split_value: #Nathan: data_set[step][1] -> data_set[step][attribute]\n",
    "                subset_split[0].append([data_set[i][0]])\n",
    "                #print subset_split\n",
    "            else:\n",
    "                subset_split[1].append([data_set[i][0]])\n",
    "                #print subset_split\n",
    "\n",
    "        subset_entropy = 0\n",
    "        intrinsic_value = 0\n",
    "\n",
    "        for value in subset_split:\n",
    "            # information gain\n",
    "            prob_value = len(value)/float(total_examples)\n",
    "            relative_entropy = entropy(value)\n",
    "\n",
    "            subset_entropy += prob_value * relative_entropy\n",
    "\n",
    "            # intrinsic value\n",
    "            ### step 2 case fails here due to 'math domain error'\n",
    "            ## ending up with prob_value = 0 at some point\n",
    "            if prob_value == 0 or prob_value == 1:\n",
    "                intrinsic_value = -1 ### just so we can catch it\n",
    "            else:\n",
    "                intrinsic_value += - prob_value * math.log(prob_value, 2)\n",
    "\n",
    "        if len(subset_split[0]) == 0 or len(subset_split[1]) == 0:\n",
    "            ratio = 0\n",
    "        else:\n",
    "            ratio = (total_entropy - subset_entropy) / intrinsic_value\n",
    "            #print (total_entropy - subset_entropy)\n",
    "\n",
    "        ratios[ratio] = temp_split_value\n",
    "\n",
    "    max_ratio = max(ratios.keys())\n",
    "    \n",
    "    if ratio < 0.0001: #Nathan: epsilon\n",
    "        return 0\n",
    "    else:\n",
    "        return ratio\n",
    "    \n",
    "    optimum_threshold = ratios[max_ratio]\n",
    "\n",
    "    output = (max_ratio, optimum_threshold)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# ======== Test case =============================\n",
    "#data_set,attr,step = [[1,0.05], [1,0.17], [1,0.64], [0,0.38], [0,0.19], [1,0.68], [1,0.69], [1,0.17], [1,0.4], [0,0.53]], 1, 2\n",
    "#print gain_ratio_numeric(data_set,attr,step) #== (0.21744375685031775, 0.19)\n",
    "#data_set,attr,step = [[1, 0.35], [1, 0.24], [0, 0.67], [0, 0.36], [1, 0.94], [1, 0.4], [1, 0.15], [0, 0.1], [1, 0.61], [1, 0.17]], 1, 4\n",
    "#print gain_ratio_numeric(data_set,attr,step) #== (0.11689800358692547, 0.94)\n",
    "#data_set,attr,step = [[1, 0.1], [0, 0.29], [1, 0.03], [0, 0.47], [1, 0.25], [1, 0.12], [1, 0.67], [1, 0.73], [1, 0.85], [1, 0.25]], 1, 1\n",
    "#print gain_ratio_numeric(data_set,attr,step) == (0.23645279766002802, 0.29)\n",
    "\n",
    "#data_set,attr,step = [[1, 0.1, 0.95], [0, 0.29, 0], [1, 0.03, 0.82], [0, 0.47, 0.03], [1, 0.25, 0.84], [1, 0.12, 0.82], [1, 0.67, 0.6], [1, 0.73, 0.6], [1, 0.85, 0.9], [1, 0.25, 0.99]], 2, 1\n",
    "#print gain_ratio_numeric(data_set,attr,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_on_nominal(data_set, attribute):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  subset of data set, the index for a nominal attribute.\n",
    "    ========================================================================================================\n",
    "    Job:    Creates a dictionary of all values of the attribute.\n",
    "    ========================================================================================================\n",
    "    Output: Dictionary of all values pointing to a list of all the data with that attribute\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for i in range(0, len(data_set)):\n",
    "        values.append(data_set[i][attribute])\n",
    "\n",
    "    unique_values = list(set(values))\n",
    "\n",
    "    values_dict = {}\n",
    "\n",
    "    for val in unique_values:\n",
    "        values_dict[val] = []\n",
    "\n",
    "    for i in range(0, len(data_set)):\n",
    "        att_value = data_set[i][attribute] #Nathan: Corrected error: data_set[i][1] -> data_set[i][attribute]\n",
    "        values_dict[att_value].append(data_set[i])\n",
    "\n",
    "    return values_dict\n",
    "\n",
    "# ======== Test case =============================\n",
    "# data_set, attr = [[0, 4], [1, 3], [1, 2], [0, 0], [0, 0], [0, 4], [1, 4], [0, 2], [1, 2], [0, 1]], 1\n",
    "# split_on_nominal(data_set, attr) == {0: [[0, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3]], 4: [[0, 4], [0, 4], [1, 4]]}\n",
    "#data_set, attr = [[1, 2], [1, 0], [0, 0], [1, 3], [0, 2], [0, 3], [0, 4], [0, 4], [1, 2], [0, 1]], 1\n",
    "#print split_on_nominal(data_set, attr) #== {0: [[1, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3], [0, 3]], 4: [[0, 4], [0, 4]]}\n",
    "#data_set, attr = [[1, 2, 2], [1, 0, 1], [0, 0, 0], [1, 3, 1], [0, 2, 1], [0, 3, 1], [0, 4, 1], [0, 4, 1], [1, 2, 2], [0, 1, 2]], 1\n",
    "#print split_on_nominal(data_set, attr) #== {0: [[1, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3], [0, 3]], 4: [[0, 4], [0, 4]]}\n",
    "\n",
    "#data_set, attr = [[0, 3, 0], [0, 3, 1], [0, 3, 1], [0, 4, 2], [0, 4, 2], [0, 4, 3], [0, 0, 0], [0, 2, 1], [1, 4, 2], [0, 4, 2]], 2\n",
    "#print split_on_nominal(data_set, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[1, 0.07], [1, 0.05]], [[0, 0.91], [0, 0.84], [1, 0.82], [0, 0.82], [0, 0.59], [0, 0.87], [0, 0.17], [1, 0.76]])\n"
     ]
    }
   ],
   "source": [
    "def split_on_numerical(data_set, attribute, splitting_value):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data set, the index for a numeric attribute, threshold (splitting) value\n",
    "    ========================================================================================================\n",
    "    Job:    Splits data_set into a tuple of two lists, the first list contains the examples where the given\n",
    "\tattribute has value less than the splitting value, the second list contains the other examples\n",
    "    ========================================================================================================\n",
    "    Output: Tuple of two lists as described above\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "\n",
    "    less_than = []\n",
    "    greater_than = []\n",
    "\n",
    "    for i in range(0, len(data_set)):\n",
    "        if data_set[i][attribute] < splitting_value:\n",
    "            less_than.append(data_set[i])\n",
    "        else:\n",
    "            greater_than.append(data_set[i])\n",
    "\n",
    "    return (less_than, greater_than)\n",
    "\n",
    "# ======== Test case =============================\n",
    "#d_set,a,sval = [[1, 0.25], [1, 0.89], [0, 0.93], [0, 0.48], [1, 0.19], [1, 0.49], [0, 0.6], [0, 0.6], [1, 0.34], [1, 0.19]],1,0.48\n",
    "#print split_on_numerical(d_set,a,sval) == ([[1, 0.25], [1, 0.19], [1, 0.34], [1, 0.19]],[[1, 0.89], [0, 0.93], [0, 0.48], [1, 0.49], [0, 0.6], [0, 0.6]])\n",
    "d_set,a,sval = [[0, 0.91], [0, 0.84], [1, 0.82], [1, 0.07], [0, 0.82],[0, 0.59], [0, 0.87], [0, 0.17], [1, 0.05], [1, 0.76]],1,0.17\n",
    "print split_on_numerical(d_set,a,sval) #== ([[1, 0.07], [1, 0.05]],[[0, 0.91],[0, 0.84], [1, 0.82], [0, 0.82], [0, 0.59], [0, 0.87], [0, 0.17], [1, 0.76]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.192270960351\n",
      "0.343187807979\n"
     ]
    }
   ],
   "source": [
    "data_set = [[0, 0, 0], [1, 0, 0], [0, 2, 1], [0, 2, 1], [0, 3, 3], [1, 1, 2], [0, 4, 1], [0, 2, 3], [1, 2, 4], [1, 5, 2]]\n",
    "attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}, {'name': \"dummy\",'is_nominal': True}]\n",
    "ratios = {}\n",
    "for i in range(1, len(data_set[0])):\n",
    "    if attribute_metadata[i]['is_nominal'] == 1: #good\n",
    "        gain_ratio = gain_ratio_nominal(data_set, i)\n",
    "        print gain_ratio\n",
    "        ratios[(i, False)] = gain_ratio\n",
    "\n",
    "\n",
    "#max_ratio = max(ratios.values())\n",
    "#best_attribute = [x for x,y in ratios.items() if y == max_ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_metadata[1]['is_nominal'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_best_attribute(data_set, attribute_metadata, numerical_splits_count):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set, attribute_metadata, splits counts for numeric\n",
    "    ========================================================================================================\n",
    "    Job:    Find the attribute that maximizes the gain ratio. If attribute is numeric return best split value.\n",
    "            If nominal, then split value is False.\n",
    "            If gain ratio of all the attributes is 0, then return False, False\n",
    "            Only consider numeric splits for which numerical_splits_count is greater than zero\n",
    "    ========================================================================================================\n",
    "    Output: best attribute, split value if numeric\n",
    "    '''\n",
    "\n",
    "    ratios = {}\n",
    "\n",
    "    for i in range(1, len(data_set[0])): # Assumes all points have same number of features, which they definitely should\n",
    "        if attribute_metadata[i]['is_nominal'] == True: #Nathan: Just changed 1 to True to fix some of my brain confusion\n",
    "            gain_ratio = gain_ratio_nominal(data_set, i)\n",
    "            ratios[(i, False)] = gain_ratio\n",
    "\n",
    "        else:\n",
    "            if numerical_splits_count[i] != 0:\n",
    "                gain_ratio = gain_ratio_numeric(data_set, i, 1) #Nathan: May have to change 1 to steps here - need to doublecheck grading method\n",
    "                ratios[(i, gain_ratio[1])] = gain_ratio[0]\n",
    "            else:\n",
    "                pass\n",
    "    if len(ratios) != 0: #Nathan: Exception handling\n",
    "        max_ratio = max(ratios.values())\n",
    "        if max_ratio != 0:\n",
    "            best_attribute = [x for x,y in ratios.items() if y == max_ratio]\n",
    "            return best_attribute[0]\n",
    "        else:\n",
    "            return (False, False)\n",
    "    else:\n",
    "        return (False, False)\n",
    "\n",
    "# # ======== Test Cases =============================\n",
    "#numerical_splits_count = [20,20,20]\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "#data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "#print pick_best_attribute(data_set, attribute_metadata, numerical_splits_count) == (1, 0.51)\n",
    "\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}]\n",
    "#data_set = [[0, 0], [1, 0], [0, 2], [0, 2], [0, 3], [1, 1], [0, 4], [0, 2], [1, 2], [1, 5]]\n",
    "#print pick_best_attribute(data_set, attribute_metadata, numerical_splits_count) == (1, False)\n",
    "\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}, {'name': \"dummy\",'is_nominal': True}]\n",
    "#data_set = [[0, 0, 0], [1, 0, 0], [0, 2, 1], [0, 2, 1], [0, 3, 3], [1, 1, 2], [0, 4, 1], [0, 2, 3], [1, 2, 4], [1, 5, 2]]\n",
    "#print pick_best_attribute(data_set, attribute_metadata, numerical_splits_count) == (2, False)\n",
    "\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': False}, {'name': \"dummy\",'is_nominal': False}]\n",
    "#data_set = [[0, 0, 0.3], [1, 0, 0.11], [0, 2, 0.7], [0, 2, 0.9], [0, 3, 0.4], [1, 1, 0.13], [0, 4, 0.1], [0, 2, 0.3], [1, 2, 0.11], [1, 5, 0.12]]\n",
    "#print pick_best_attribute(data_set, attribute_metadata, numerical_splits_count)\n",
    "\n",
    "# Uses gain_ratio_nominal or gain_ratio_numeric to calculate gain ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start changing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e8ca1cc5022b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mdata_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.27\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.86\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.68\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.51\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mnumerical_splits_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mID3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_splits_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;31m#if n and [n.classify(x) == x[0] for x in data_set] == [True, False, True, True, False, True, True, True, True, True, True]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-e8ca1cc5022b>\u001b[0m in \u001b[0;36mID3\u001b[0;34m(data_set, attribute_metadata, numerical_splits_count, depth)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;31m# Finished with this branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mbest_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_best_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_splits_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_attribute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nominal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattribute_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_nominal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-5eb189b4a74a>\u001b[0m in \u001b[0;36mpick_best_attribute\u001b[0;34m(data_set, attribute_metadata, numerical_splits_count)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumerical_splits_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mgain_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain_ratio_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Nathan: May have to change 1 to steps here - need to doublecheck grading method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mratios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgain_ratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain_ratio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "def ID3(data_set, attribute_metadata, numerical_splits_count, depth):\n",
    "    '''\n",
    "    See Textbook for algorithm.\n",
    "    Make sure to handle unknown values, some suggested approaches were\n",
    "    given in lecture.\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set, attribute_metadata, maximum number of splits to consider for numerical attributes,\n",
    "\tmaximum depth to search to (depth = 0 indicates that this node should output a label)\n",
    "    ========================================================================================================\n",
    "    Output: The node representing the decision tree learned over the given data set\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "\n",
    "    root = Node()\n",
    "    print depth\n",
    "    if depth == 0: #Depth check\n",
    "        root.label = mode(data_set)\n",
    "    else:\n",
    "        root.label = check_homogenous(data_set)\n",
    "        \n",
    "    if root.label != None: #If data set isn't homogeneous or max depth\n",
    "        return root # Finished with this branch\n",
    "    else:\n",
    "        best_att = pick_best_attribute(data_set, attribute_metadata, numerical_splits_count)\n",
    "        root.decision_attribute = best_att[0]\n",
    "        root.is_nominal = attribute_metadata[best_att[0]]['is_nominal']\n",
    "        root.splitting_value = best_att[1]\n",
    "        print best_att\n",
    "    #outcomes = [] # this is the classes in the data_set - #Nathan: moved all this to check_homogeneous\n",
    "    #for i in range(0, len(data_set)):\n",
    "    #    outcomes.append([data_set[i][0]])\n",
    "    #done = check_homogenous(outcomes)\n",
    "    #root.label = done\n",
    "    \n",
    "        root.name = attribute_metadata[best_att[0]]['name']      \n",
    "        child_numerical_splits_count = numerical_splits_count\n",
    "    ### this is not correct\n",
    "    # root.children should not have subset datasets in values for each attribute thing\n",
    "        if root.is_nominal == True:\n",
    "            root.children = {}\n",
    "            data = split_on_nominal(data_set, root.decision_attribute)\n",
    "            sub_depth = depth - 1\n",
    "            for i in data.keys():\n",
    "                new_node = ID3(data[i], attribute_metadata, child_numerical_splits_count, sub_depth)\n",
    "                #print new_node, 'nom'\n",
    "                #print [new_node.classify(x) == x[0] for x in data_set]\n",
    "                root.children[i] = new_node\n",
    "            #root.children = split_on_nominal(data_set, root.decision_attribute)\n",
    "            \n",
    "        elif root.is_nominal == False:\n",
    "            root.children = []\n",
    "            data = split_on_numerical(data_set, root.decision_attribute, root.splitting_value)\n",
    "            child_numerical_splits_count[root.decision_attribute] = child_numerical_splits_count[root.decision_attribute]-1\n",
    "            sub_depth = depth - 1\n",
    "            for i in range(len(data)):\n",
    "                new_node = ID3(data[i], attribute_metadata, child_numerical_splits_count, sub_depth)\n",
    "                #print new_node, 'num'\n",
    "                root.children.append(new_node)\n",
    "        \n",
    "        else:\n",
    "            print 'Troubles brewing'\n",
    "            \n",
    "    return root\n",
    "\n",
    "#                best_feature_values = {s.sample[best_feature]\n",
    "#                                       for s in training_samples}\n",
    "#                for value in best_feature_values:\n",
    "#                    samples = [s for s in training_samples\n",
    "#                               if s.sample[best_feature] == value]\n",
    "#                    # Recursively, create a child node.\n",
    "#                    root.children = create_decision_tree(samples,\n",
    "#                                                      predicting_features)\n",
    "#                    root_node[value] = child\n",
    "#        return root_node\n",
    "    \n",
    "    \n",
    "    #while tree.label == None:\n",
    "    # GenerateTree(X)\n",
    "    # If NodeEntropy(X) < ThresholdI   **entropy equation 9.3 <---- function below\n",
    "                        ## threshold = 0.001\n",
    "        # Create leaf labelled by majority class in X\n",
    "                        ## mode function\n",
    "        # Return\n",
    "\n",
    "    #pick_best_attribute(data_set, attribute_metadata, numerical_splits_count)\n",
    "    # i <- SplitAttribute(X)\n",
    "    # For each branch of xi\n",
    "        # Find Xi falling in branch\n",
    "        # GenerateTree(Xi)\n",
    "\n",
    "    # SplitAttribute(X) ## pick_best_attribute()\n",
    "        # MinEnt <- MAX\n",
    "        # For all attributes i = 1, ... , d\n",
    "            # if Xi is discrete with n values\n",
    "                # Split X into X1, ..., Xn by xi\n",
    "                # e <- SplitEntropy(X1, ..., Xn) ** impurity equation 9.8\n",
    "                # if e<MinEnt MinEnt <- e; bestf <- i\n",
    "            # Else /* xi is numeric*/\n",
    "                # For all possible splits\n",
    "                    # Split X into X1, X2, on xi\n",
    "                    # e <- SplitEntropy(X1, X2)\n",
    "                    # If e<MinEnt MinEnt <- 3; bestf <- i\n",
    "        # Return bestf\n",
    "\n",
    "    ## for all attributes, calculate impurity and choose the one that has the minimum entropy (measured by equation 9.8)\n",
    "\n",
    "\n",
    "    # somewhere deal with the numerical_splits_count thing\n",
    "\n",
    "#numerical_split_counts = [20, 20, 20]\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}, {'name': \"dummy\",'is_nominal': True}]\n",
    "#data_set = [[0, 0, 2], [1, 0, 3], [0, 2, 1], [0, 2, 3], [0, 3, 2], [1, 1, 1], [0, 4, 3], [0, 2, 3], [1, 2, 3], [1, 5, 0]]\n",
    "#print ID3(data_set, attribute_metadata, numerical_split_counts, depth = 5)\n",
    "\n",
    "#numerical_split_counts = [20, 20, 20]\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}, {'name': \"dummy\",'is_nominal': False}]\n",
    "#data_set = [[0, 0, 0.3], [1, 0, 0.11], [0, 2, 0.7], [0, 2, 0.9], [0, 3, 0.4], [1, 1, 0.13], [0, 4, 0.1], [0, 2, 0.3], [1, 2, 0.11], [1, 5, 0.12]]\n",
    "#print ID3(data_set, attribute_metadata, numerical_split_counts, depth = 5)\n",
    "\n",
    "#numerical_split_counts = [20, 20, 20]\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}, {'name': \"dummy\",'is_nominal': False}]\n",
    "#data_set = [[0, 0, 0.1], [1, 0, 8], [0, 2, 0.2], [0, 2, 0.1], [0, 3, 0.4], [1, 1, 10], [0, 4, 0.1], [0, 2, 0.1], [1, 2, 15], [1, 5, 3]]\n",
    "#print ID3(data_set, attribute_metadata, numerical_split_counts, depth = 0)\n",
    "\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "#data_set = [[0, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [0, 0.01], [0, 0.33], [0, 0.42], [0, 0.42], [0, 0.51], [0, 0.4]]\n",
    "#numerical_splits_count = [5, 5]\n",
    "#print ID3(data_set, attribute_metadata, numerical_splits_count, 0)\n",
    "\n",
    "#attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "#data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "#numerical_splits_count = [1, 1]\n",
    "#n = ID3(data_set, attribute_metadata, numerical_splits_count, 5)\n",
    "#print n == [True, False, True, True, False, True, True, True, True, True, True]\n",
    "\n",
    "attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "numerical_splits_count = [1, 1]\n",
    "print ID3(data_set, attribute_metadata, numerical_splits_count, 5)\n",
    "#if n and [n.classify(x) == x[0] for x in data_set] == [True, False, True, True, False, True, True, True, True, True, True]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = {0: [[0, 0, 2], [1, 0, 3]], 1: [[1, 1, 1]], 2: [[0, 2, 1], [0, 2, 3], [0, 2, 3], [1, 2, 3]], 3: [[0, 3, 2]], 4: [[0, 4, 3]], 5: [[1, 5, 0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-326-82012084a99c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-326-82012084a99c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for 2:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for 2:\n",
    "    print[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 2], [1, 0, 3]]\n",
      "[[1, 1, 1]]\n",
      "[[0, 2, 1], [0, 2, 3], [0, 2, 3], [1, 2, 3]]\n",
      "[[0, 3, 2]]\n",
      "[[0, 4, 3]]\n",
      "[[1, 5, 0]]\n"
     ]
    }
   ],
   "source": [
    "for i in w.keys():\n",
    "    print w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from ID3 import *\n",
    "from operator import xor\n",
    "from parse import parse\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from pruning import validation_accuracy\n",
    "\n",
    "# NOTE: these functions are just for your reference, you will NOT be graded on their output\n",
    "# so you can feel free to implement them as you choose, or not implement them at all if you want\n",
    "# to use an entirely different method for graphing\n",
    "\n",
    "def get_graph_accuracy_partial(train_set, attribute_metadata, validate_set, numerical_splits_count, pct):\n",
    "    '''\n",
    "    get_graph_accuracy_partial - Given a training set, attribute metadata, validation set, numerical splits count, and percentage,\n",
    "    this function will return the validation accuracy of a specified (percentage) portion of the trainging setself.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def get_graph_data(train_set, attribute_metadata, validate_set, numerical_splits_count, iterations, pcts):\n",
    "    '''\n",
    "    Given a training set, attribute metadata, validation set, numerical splits count, iterations, and percentages,\n",
    "    this function will return an array of the averaged graph accuracy partials based off the number of iterations.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "# get_graph will plot the points of the results from get_graph_data and return a graph\n",
    "def get_graph(train_set, attribute_metadata, validate_set, numerical_splits_count, depth, iterations, lower, upper, increment):\n",
    "    '''\n",
    "    get_graph - Given a training set, attribute metadata, validation set, numerical splits count, depth, iterations, lower(range),\n",
    "    upper(range), and increment, this function will graph the results from get_graph_data in reference to the drange\n",
    "    percentages of the data.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnewInstance = [1, 0.6, 1, 0] # outcome, homeaway, dayssincegame, weather\\nattNames = [\"outcome\", \"homeaway\", \"dayssincegame\", \"weather\"]\\n\\ntree = Node()\\nsubtree1 = Node()\\nsubtree2 = Node()\\n #output nodes\\nn0 = Node()\\nn0.label = 0\\nn1 = Node()\\nn1.label = 1\\n\\n\\ntree.decision_attribute = 1\\ntree.name = \"dayssincegame\"\\ntree.is_nominal = False\\ntree.splitting_value = 2\\ntree.children = [subtree1, subtree2]\\n\\nsubtree1.decision_attribute = 2\\nsubtree1.name = \"homeaway\"\\nsubtree1.is_nominal = True\\nsubtree1.children = {1: subtree2, 0: n0}\\n\\nsubtree2.decision_attribute = 3\\nsubtree2.name = \"weather\"\\nsubtree2.is_nominal = True\\nsubtree2.children = {0: n1, 1: n0, -1: n0}\\n\\noutput = tree.classify(newInstance)\\n\\nprint output\\n'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOCUMENTATION\n",
    "# =====================================\n",
    "# Class node attributes:\n",
    "# ----------------------------\n",
    "# children - a list of 2 if numeric and a dictionary if nominal.  \n",
    "#            For numeric, the 0 index holds examples < the splitting_value, the \n",
    "#            1 index holds examples >= the splitting value\n",
    "#\n",
    "# label - is None if there is a decision attribute, and is the output label (0 or 1 for\n",
    "#\tthe homework data set) if there are no other attributes\n",
    "#       to split on or the data is homogenous\n",
    "#\n",
    "# decision_attribute - the index of the decision attribute being split on\n",
    "#\n",
    "# is_nominal - is the decision attribute nominal\n",
    "#\n",
    "# value - Ignore (not used, output class if any goes in label)\n",
    "#\n",
    "# splitting_value - if numeric, where to split\n",
    "#\n",
    "# name - name of the attribute being split on\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        # initialize all attributes\n",
    "        self.label = None\n",
    "        self.decision_attribute = None\n",
    "        self.is_nominal = None\n",
    "        #self.value = None\n",
    "        self.splitting_value = None\n",
    "        self.children = None #Nathan - checkign\n",
    "        self.name = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.label)\n",
    "\n",
    "    def classify(self, instance):\n",
    "        '''\n",
    "        given a single observation, will return the output of the tree\n",
    "        '''\n",
    "\n",
    "        current_label = self.label\n",
    "\n",
    "        if current_label == 1:\n",
    "            return current_label\n",
    "\n",
    "        else:\n",
    "            node_index = self.decision_attribute\n",
    "            att_value = instance[node_index]\n",
    "            current_children = self.children\n",
    "            split_value = self.splitting_value\n",
    "            nominal = self.is_nominal\n",
    "\n",
    "            while current_label == None:\n",
    "                if nominal == False:\n",
    "                    \n",
    "                    split_on = split_value\n",
    "\n",
    "                    if att_value < split_on:\n",
    "                        next_node = current_children[0]\n",
    "\n",
    "                    else:\n",
    "                        next_node = current_children[1]\n",
    "\n",
    "                else:\n",
    "                    next_node = current_children[att_value]\n",
    "\n",
    "                current_label = next_node.label\n",
    "\n",
    "                if current_label != None:\n",
    "                    return current_label\n",
    "\n",
    "                else:\n",
    "                    node_index = next_node.decision_attribute\n",
    "                    att_value = instance[node_index]\n",
    "                    current_children = next_node.children\n",
    "                    nominal = next_node.is_nominal\n",
    "                    split_value = next_node.splitting_value\n",
    "\n",
    "            return next_node\n",
    "        \n",
    "    #for i in data.keys():\n",
    "    #    root.children.add[i] = child_node\n",
    "        \n",
    "    def print_tree(self, indent = 0):\n",
    "        '''\n",
    "        returns a string of the entire tree in human readable form\n",
    "        '''\n",
    "        # Your code here\n",
    "    \t# Nodes whose children are Nodes printed out\n",
    "\n",
    "        # name of current attribute is one of attribues for Node object\n",
    "        # series of if-then statements?\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    def print_dnf_tree(self):\n",
    "        '''\n",
    "        returns the disjunct normalized form of the tree.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "\"\"\"\n",
    "newInstance = [1, 0.6, 1, 0] # outcome, homeaway, dayssincegame, weather\n",
    "attNames = [\"outcome\", \"homeaway\", \"dayssincegame\", \"weather\"]\n",
    "\n",
    "tree = Node()\n",
    "subtree1 = Node()\n",
    "subtree2 = Node()\n",
    " #output nodes\n",
    "n0 = Node()\n",
    "n0.label = 0\n",
    "n1 = Node()\n",
    "n1.label = 1\n",
    "\n",
    "\n",
    "tree.decision_attribute = 1\n",
    "tree.name = \"dayssincegame\"\n",
    "tree.is_nominal = False\n",
    "tree.splitting_value = 2\n",
    "tree.children = [subtree1, subtree2]\n",
    "\n",
    "subtree1.decision_attribute = 2\n",
    "subtree1.name = \"homeaway\"\n",
    "subtree1.is_nominal = True\n",
    "subtree1.children = {1: subtree2, 0: n0}\n",
    "\n",
    "subtree2.decision_attribute = 3\n",
    "subtree2.name = \"weather\"\n",
    "subtree2.is_nominal = True\n",
    "subtree2.children = {0: n1, 1: n0, -1: n0}\n",
    "\n",
    "output = tree.classify(newInstance)\n",
    "\n",
    "print output\n",
    "\"\"\"\n",
    "#output from parse:\n",
    "#data[0] = array of arrays with attribute values\n",
    "#data[1] = dictionary {is_nominal: T/F, name: attributeName}\n",
    "#running decision_tree_driver:\n",
    "#train_set = data[0]\n",
    "#attribute_metadata = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== homogenous ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "Passed 3\n",
      "All tests passed\n",
      "========== pick_best_attribute ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "All tests passed\n",
      "========== mode ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "All tests passed\n",
      "========== entropy ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "Passed 3\n",
      "All tests passed\n",
      "========== gain_ratio_nominal ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "Passed 3\n",
      "All tests passed\n",
      "========== gain_ratio_numeric ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "Passed 3\n",
      "All tests passed\n",
      "========== split_on_nominal ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "All tests passed\n",
      "========== split_on_numerical ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "All tests passed\n",
      "========== classify ==========\n",
      "Passed 1\n",
      "Passed 2\n",
      "All tests passed\n",
      "========== ID3 ==========\n",
      "Passed 1\n",
      "0\n",
      "1\n",
      "None\n",
      "0\n",
      "Failed 2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "Failed 3\n",
      "not all tests passed, please see ID3.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#from modules.ID3 import *\n",
    "#from modules.parse import *\n",
    "#from modules.pruning import *\n",
    "#from modules.graph import *\n",
    "#from modules.predictions import *\n",
    "#from modules.pickled import *\n",
    "\n",
    "EPSILON = 0.001\n",
    "\n",
    "## Running File\n",
    "#\n",
    "# To run this file select either True or False for each of the options input\n",
    "# This will use the function found in ID3 or pruning to run the tests and let you know how your algorithm performed.\n",
    "# If there is an error or a test has been failed please look over your algorithm and try again.\n",
    "#\n",
    "options = {\n",
    "\t'homogenous': True,\n",
    "\t'gain_ratio_numeric': True,\n",
    "\t'split_on_nominal': True,\n",
    "    'split_on_numerical': True,\n",
    "    'p_best_attribute': True,\n",
    "    'mode': True,\n",
    "    'entropy': True,\n",
    "    'gain_ratio_nominal':True,\n",
    "    'classify': True\n",
    "}\n",
    "\n",
    "def grader(homogenous=False,p_best_attribute=False,mode=False,entropy=False,gain_ratio_nominal=False,split_on_nominal=False,split_on_numerical=False, gain_ratio_numeric=False, classify=False):\n",
    "\ttitle = \"==========\"\n",
    "\tgain_ratio_result = True\n",
    "\tif homogenous:\n",
    "\t\tname = \"homogenous\"\n",
    "\t\tprint title,name,title\n",
    "\t\ttotal = 0\n",
    "\t\tdata_set = [[[0],[1],[1],[1],[1],[1]],[[0],[1],[None],[0]],[[1],[1],[1],[1],[1],[1]]]\n",
    "\t\tresult = [None,None,1]\n",
    "\t\tfor i in xrange(3):\n",
    "\t\t\tif check_homogenous(data_set[i]) == result[i]:\n",
    "\t\t\t\ttotal += 1\n",
    "\t\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\t\tprint \"Not all tests were met please look at %s\"%name if total != 3 else \"All tests passed\"\n",
    "\tif p_best_attribute:\n",
    "\t\tname = \"pick_best_attribute\"\n",
    "\t\tprint title,name,title\n",
    "\t\tnumerical_splits_count = [20,20]\n",
    "\t\ta_meta = [[{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "\t\t,[{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}]]\n",
    "\n",
    "\t\td_set = [[[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [0, 0.51], [1, 0.4]],\n",
    "\t\t[[0, 0], [1, 0], [0, 2], [0, 2], [0, 3], [1, 1], [0, 4], [0, 2], [1, 2], [1, 5]]]\n",
    "\t\tresult = [(1, 0.51),(1, False)]\n",
    "\t\ttotal = 0\n",
    "\t\tfor i in xrange(2):\n",
    "\t\t\tif pick_best_attribute(d_set[i], a_meta[i], numerical_splits_count) == result[i]:\n",
    "\t\t\t\ttotal += 1\n",
    "\t\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\t\tprint \"Not all tests were met please look at %s\"%name if total != 2 else \"All tests passed\"\n",
    "\tif mode:\n",
    "\t\tname = \"mode\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_mode()\n",
    "\tif entropy:\n",
    "\t\tname = \"entropy\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_entropy()\n",
    "\tif gain_ratio_nominal:\n",
    "\t\tname = \"gain_ratio_nominal\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_gain_ratio_nom()\n",
    "\tif gain_ratio_numeric:\n",
    "\t\tname = \"gain_ratio_numeric\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_gain_ratio_num()\n",
    "\tif split_on_nominal:\n",
    "\t\tname = \"split_on_nominal\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_split_on_nominal()\n",
    "\tif split_on_numerical:\n",
    "\t\tname = \"split_on_numerical\"\n",
    "\t\tprint title,name,title\n",
    "\t\tprint \"Not all tests were met please look at %s\"%name if split_o_num(name) is not 2 else \"All tests passed\"\n",
    "\tif classify:\n",
    "\t\tname = \"classify\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_classify()\n",
    "        if ID3:\n",
    "\t\tname = \"ID3\"\n",
    "\t\tprint title,name,title\n",
    "\t\tcheck_ID3()\n",
    "\n",
    "def create_data_set(typ):\n",
    "\treturn [[random.randint(0,1) if y is 0 else (round(random.random(),2) if typ is 'numeric' else random.randint(0,\n",
    "\t\t5)) for y in xrange(2)] for x in xrange(10)]\n",
    "\n",
    "def split_o_num(name):\n",
    "\tsval = [0.48,0.17]\n",
    "\td_set = [[[1, 0.25], [1, 0.89], [0, 0.93], [0, 0.48], [1, 0.19], [1, 0.49], [0, 0.6], [0, 0.6], [1, 0.34], [1, 0.19]]]\n",
    "\td_set.append([[0, 0.91], [0, 0.84], [1, 0.82], [1, 0.07], [0, 0.82],[0, 0.59], [0, 0.87], [0, 0.17], [1, 0.05], [1, 0.76]])\n",
    "\tresult = [([[1, 0.25], [1, 0.19], [1, 0.34], [1, 0.19]],[[1, 0.89], [0, 0.93], [0, 0.48], [1, 0.49], [0, 0.6], [0, 0.6]])]\n",
    "\tresult.append(([[1, 0.07], [1, 0.05]],[[0, 0.91],[0, 0.84], [1, 0.82], [0, 0.82], [0, 0.59], [0, 0.87], [0, 0.17], [1, 0.76]]))\n",
    "\ttotal = 0\n",
    "\tfor i in xrange(2):\n",
    "\t\tif split_on_numerical(d_set[i],1,sval[i]) == result[i]:\n",
    "\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\ttotal += 1\n",
    "\t\telse:\n",
    "\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\treturn total\n",
    "\n",
    "def check_mode():\n",
    "\tdata_set = [[[0],[1],[1],[1],[1],[1]],[[0],[1],[0],[0]]]\n",
    "\tresult = [1,0]\n",
    "\tprinting_results(data_set,result,mode)\n",
    "\n",
    "def check_entropy():\n",
    "\tdata_set = [[[0],[1],[1],[1],[0],[1],[1],[1]],[[0],[0],[1],[1],[0],[1],[1],[0]],[[0],[0],[0],[0],[0],[0],[0],[0]]]\n",
    "\tresult = [0.811,1.0,0]\n",
    "\tprinting_results(data_set,result,entropy)\n",
    "\n",
    "def check_gain_ratio_nom():\n",
    "\tattr = 1\n",
    "\tdata_set = [[[1, 2], [1, 0], [1, 0], [0, 2], [0, 2], [0, 0], [1, 3], [0, 4], [0, 3], [1, 1]]\n",
    "\t,[[1, 2], [1, 2], [0, 4], [0, 0], [0, 1], [0, 3], [0, 0], [0, 0], [0, 4], [0, 2]]\n",
    "\t,[[0, 3], [0, 3], [0, 3], [0, 4], [0, 4], [0, 4], [0, 0], [0, 2], [1, 4], [0, 4]]]\n",
    "\tresult = [0.11470666361703151, 0.2056423328155741, 0.06409559743967516]\n",
    "\ttotal = 0\n",
    "\tfor i in xrange(len(data_set)):\n",
    "\t\tGRNom = gain_ratio_nominal(data_set[i],attr)\n",
    "\t\tif GRNom is not None and abs(GRNom - result[i]) < EPSILON:\n",
    "\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\ttotal += 1\n",
    "\t\telse:\n",
    "\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\tprint \"Not all tests were met please look at gain_ratio_nominal\" if total != len(result) else \"All tests passed\"\n",
    "\n",
    "def check_gain_ratio_num():\n",
    "\tstep = [2,4,1]\n",
    "\tdata_set = [[[0,0.05], [1,0.17], [1,0.64], [0,0.38], [0,0.19], [1,0.68], [1,0.69], [1,0.17], [1,0.4], [0,0.53]]\n",
    "\t,[[1, 0.35], [1, 0.24], [0, 0.67], [0, 0.36], [1, 0.94], [1, 0.4], [1, 0.15], [0, 0.1], [1, 0.61], [1, 0.17]]\n",
    "\t,[[1, 0.1], [0, 0.29], [1, 0.03], [0, 0.47], [1, 0.25], [1, 0.12], [1, 0.67], [1, 0.73], [1, 0.85], [1, 0.25]]]\n",
    "\tresult = [(0.31918053332474033, 0.64),(0.11689800358692547, 0.94),(0.23645279766002802, 0.29)]\n",
    "\ttotal = 0\n",
    "\tfor i in xrange(3):\n",
    "\t\tGRNum = gain_ratio_numeric(data_set[i],1,step[i])\n",
    "\t\tif GRNum is not None and reduce(lambda x,y: x and y, (abs(x - y) < EPSILON for x,y in zip(GRNum, result[i]))):\n",
    "\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\ttotal += 1\n",
    "\t\telse:\n",
    "\t\t \tprint \"Failed %d\"%(i+1)\n",
    "\tprint \"Not all tests were met please look at gain_ratio_num\" if total != len(result) else \"All tests passed\"\n",
    "\n",
    "def check_split_on_nominal():\n",
    "\tattr = 1\n",
    "\tdata_set = [[[0, 4], [1, 3], [1, 2], [0, 0], [0, 0], [0, 4], [1, 4], [0, 2], [1, 2], [0, 1]],\n",
    "\t[[1, 2], [1, 0], [0, 0], [1, 3], [0, 2], [0, 3], [0, 4], [0, 4], [1, 2], [0, 1]]]\n",
    "\tresult = [{0: [[0, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3]], 4: [[0, 4], [0, 4], [1, 4]]}\n",
    "\t,{0: [[1, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3], [0, 3]], 4: [[0, 4], [0, 4]]}]\n",
    "\ttotal = 0\n",
    "\tfor i in xrange(len(data_set)):\n",
    "\t\tif split_on_nominal(data_set[i],1) == result[i]:\n",
    "\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\ttotal += 1\n",
    "\t\telse:\n",
    "\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\tprint \"Not all tests were met please look at split_on_nominal\" if total != len(result) else \"All tests passed\"\n",
    "\n",
    "def printing_results(data_set,result,function):\n",
    "\ttotal = 0\n",
    "\tfor i in xrange(len(data_set)):\n",
    "\t\tprintfunc = function(data_set[i])\n",
    "\t\tif printfunc is not None and abs(printfunc - result[i]) < EPSILON:\n",
    "\t\t\tprint \"Passed %d\"%(i+1)\n",
    "\t\t\ttotal += 1\n",
    "\t\telse:\n",
    "\t\t\tprint \"Failed %d\"%(i+1)\n",
    "\tprint \"Not all tests were met please look at %s\"% function.__name__ if total != len(result) else \"All tests passed\"\n",
    "\n",
    "def check_classify():\n",
    "\tn0 = Node()\n",
    "\tn0.label = 1\n",
    "\ti = 0;\n",
    "\tif n0.classify([0, 1, 2]) == 1:\n",
    "\t\tprint \"Passed 1\"\n",
    "\t\ti += 1\n",
    "\telse:\n",
    "\t\tprint \"Failed 1\"\n",
    "\tn1 = Node()\n",
    "\tn1.label = 0\n",
    "\tn = Node()\n",
    "\tn.label = None\n",
    "\tn.decision_attribute = 1\n",
    "\tn.is_nominal = True\n",
    "\tn.name = \"You saw the attributes what do you think?\"\n",
    "\tn.children = {1: n0, 2: n1}\n",
    "#\tprint n\n",
    "\tif n.classify([0, 2]) == 0:\n",
    "\t\tprint \"Passed 2\"\n",
    "\t\ti += 1\n",
    "\telse:\n",
    "\t\tprint \"Failed 2\"\n",
    "\tif i == 2:\n",
    "\t\tprint \"All tests passed\"\n",
    "\telse:\n",
    "\t\tprint \"Not all tests passed, look at classify\"\n",
    "\n",
    "def check_ID3():\n",
    "   attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "   data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "   numerical_splits_count = [5, 5]\n",
    "   n = ID3(data_set, attribute_metadata, numerical_splits_count, 0)\n",
    "   fails = 0;\n",
    "   if n and n.label == 1:\n",
    "      print \"Passed 1\"\n",
    "   else:\n",
    "      print \"Failed 1\"\n",
    "      fails += 1\n",
    "   attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "   data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "   numerical_splits_count = [1, 1]\n",
    "   n = ID3(data_set, attribute_metadata, numerical_splits_count, 5)\n",
    "   if n and [n.classify(x) == x[0] for x in data_set] == [True, False, True, True, False, True, True, True, True, True, True]:\n",
    "      print \"Passed 2\"\n",
    "   else:\n",
    "      print \"Failed 2\"\n",
    "      fails += 1\n",
    "\n",
    "   attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "   data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "   numerical_splits_count = [5, 5]\n",
    "   n = ID3(data_set, attribute_metadata, numerical_splits_count, 5)\n",
    "   if n and [n.classify(x) == x[0] for x in data_set] == [True, False, True, True, True, True, True, True, True, True, True]:\n",
    "      print \"Passed 3\"\n",
    "   else:\n",
    "      print \"Failed 3\"\n",
    "      fails += 1\n",
    "   if fails > 0:\n",
    "      print \"not all tests passed, please see ID3.\"\n",
    "   else:\n",
    "      print \"all tests passed.\"\n",
    "test = grader( **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from operator import xor\n",
    "from parse import *\n",
    "\n",
    "# DOCUMENTATION\n",
    "# ========================================\n",
    "# this function outputs predictions for a given data set.\n",
    "# NOTE this function is provided only for reference.\n",
    "# You will not be graded on the details of this function, so you can change the interface if \n",
    "# you choose, or not complete this function at all if you want to use a different method for\n",
    "# generating predictions.\n",
    "\n",
    "def create_predictions(tree, predict):\n",
    "    '''\n",
    "    Given a tree and a url to a data_set. Create a csv with a prediction for each result\n",
    "    using the classify method in node class.\n",
    "    '''\n",
    "    #### use classify method to make predictions from an unlabeled test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from node import Node\n",
    "from ID3 import *\n",
    "from operator import xor\n",
    "\n",
    "# Note, these functions are provided for your reference.  You will not be graded on their behavior,\n",
    "# so you can implement them as you choose or not implement them at all if you want to use a different\n",
    "# architecture for pruning.\n",
    "\n",
    "def reduced_error_pruning(root,training_set,validation_set):\n",
    "    '''\n",
    "    take the a node, training set, and validation set and returns the improved node.\n",
    "    You can implement this as you choose, but the goal is to remove some nodes such that doing so improves validation accuracy.\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# \n",
    "\n",
    "def validation_accuracy(tree,validation_set):\n",
    "    '''\n",
    "    takes a tree and a validation set and returns the accuracy of the set on the given tree\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
