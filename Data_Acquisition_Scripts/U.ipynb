{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Node.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DOCUMENTATION\n",
    "# =====================================\n",
    "# Class node attributes:\n",
    "# ----------------------------\n",
    "# children - a list of 2 if numeric and a dictionary if nominal for numeric, 0 if for < and 1 for >=\n",
    "#\n",
    "# label - is None if there is a decision attribute, and is 0 or 1 if there are no other attributes\n",
    "#       to split on or the data is homogenous\n",
    "#\n",
    "# decision_attribute - the decision attribute being splitted on\n",
    "#\n",
    "# is_nominal - is the decision attribute nominal\n",
    "#\n",
    "# value - if label is None this should be None.\n",
    "#         if label is 0, this should be the mode.\n",
    "#         if label is 1, this should be the homogenous value\n",
    "#\n",
    "# splitting_value - if numeric, where to split\n",
    "#\n",
    "# name - name of the attribute being split on\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        # initialize all attributes\n",
    "        self.label = None\n",
    "        self.decision_attribute = None\n",
    "        self.is_nominal = None\n",
    "        self.value = None\n",
    "        self.splitting_value = None\n",
    "        self.children = {}\n",
    "        self.name = None\n",
    "\n",
    "    def classify(self, instance):\n",
    "        '''\n",
    "        given a single observation, will return the output of the tree\n",
    "        '''\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "\n",
    "    def print_tree(self, indent = 0):\n",
    "        '''\n",
    "        returns a string of the entire tree in human readable form\n",
    "        '''\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "\n",
    "    def print_dnf_tree(self):\n",
    "        '''\n",
    "        returns the disjunct normalized form of the tree.\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ID3.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from node import Node\n",
    "import sys\n",
    "\n",
    "def ID3(data_set, attribute_metadata, numerical_splits_count, depth):\n",
    "    '''\n",
    "    See Textbook for algorithm.\n",
    "    Make sure to handle unknown values, some suggested approaches were\n",
    "    given in lecture.\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def check_homogenous(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Checks if the attribute at index 0 is the same for the data_set, if so return output otherwise None.\n",
    "    ========================================================================================================\n",
    "    Output: Return either the homogenous attribute or None\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test Cases =============================\n",
    "# data_set = [[0],[1],[1],[1],[1],[1]]\n",
    "# check_homogenous(data_set) ==  None\n",
    "# data_set = [[0],[1],[None],[0]]\n",
    "# check_homogenous(data_set) ==  None\n",
    "# data_set = [[1],[1],[1],[1],[1],[1]]\n",
    "# check_homogenous(data_set) ==  1\n",
    "\n",
    "def pick_best_attribute(data_set, attribute_metadata, numerical_splits_count):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set, attribute_metadata, splits counts for numeric\n",
    "    ========================================================================================================\n",
    "    Job:    Find the attribute that maximizes the gain ratio. If attribute is numeric return best split value.\n",
    "            If nominal, then split value is False.\n",
    "            If gain ratio of all the attributes is 0, then return False, False\n",
    "    ========================================================================================================\n",
    "    Output: best attribute, split value if numeric\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# # ======== Test Cases =============================\n",
    "# numerical_splits_count = [20,20]\n",
    "# attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"opprundifferential\",'is_nominal': False}]\n",
    "# data_set = [[1, 0.27], [0, 0.42], [0, 0.86], [0, 0.68], [0, 0.04], [1, 0.01], [1, 0.33], [1, 0.42], [0, 0.51], [1, 0.4]]\n",
    "# pick_best_attribute(data_set, attribute_metadata, numerical_splits_count) == (1, 0.51)\n",
    "# attribute_metadata = [{'name': \"winner\",'is_nominal': True},{'name': \"weather\",'is_nominal': True}]\n",
    "# data_set = [[0, 0], [1, 0], [0, 2], [0, 2], [0, 3], [1, 1], [0, 4], [0, 2], [1, 2], [1, 5]]\n",
    "# pick_best_attribute(data_set, attribute_metadata, numerical_splits_count) == (1, False)\n",
    "\n",
    "# Uses gain_ratio_nominal or gain_ratio_numeric to calculate gain ratio.\n",
    "\n",
    "def mode(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Takes a data_set and finds mode of index 0.\n",
    "    ========================================================================================================\n",
    "    Output: mode of index 0.\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# data_set = [[0],[1],[1],[1],[1],[1]]\n",
    "# mode(data_set) == 1\n",
    "# data_set = [[0],[1],[0],[0]]\n",
    "# mode(data_set) == 0\n",
    "\n",
    "def entropy(data_set):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  A data_set\n",
    "    ========================================================================================================\n",
    "    Job:    Calculates the entropy of the attribute at the 0th index, the value we want to predict.\n",
    "    ========================================================================================================\n",
    "    Output: Returns entropy. Number between 0-1. See Textbook for formula\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# data_set = [[0],[1],[1],[1],[0],[1],[1],[1]]\n",
    "# entropy(data_set) == 0.811\n",
    "# data_set = [[0],[0],[1],[1],[0],[1],[1],[0]]\n",
    "# entropy(data_set) == 1.0\n",
    "# data_set = [[0],[0],[0],[0],[0],[0],[0],[0]]\n",
    "# entropy(data_set) == 0\n",
    "\n",
    "\n",
    "def gain_ratio_nominal(data_set, attribute):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data_set, index for a nominal attribute\n",
    "    ========================================================================================================\n",
    "    Job:    Finds the gain ratio of a nominal attribute in relation to the variable we are training on.\n",
    "    ========================================================================================================\n",
    "    Output: Returns gain_ratio. See https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# data_set, attr = [[1, 2], [1, 0], [1, 0], [0, 2], [0, 2], [0, 0], [1, 3], [0, 4], [0, 3], [1, 1]], 1\n",
    "# gain_ratio_nominal(data_set,attr) == 0.11470666361703151\n",
    "# data_set, attr = [[1, 2], [1, 2], [0, 4], [0, 0], [0, 1], [0, 3], [0, 0], [0, 0], [0, 4], [0, 2]], 1\n",
    "# gain_ratio_nominal(data_set,attr) == 0.2056423328155741\n",
    "# data_set, attr = [[0, 3], [0, 3], [0, 3], [0, 4], [0, 4], [0, 4], [0, 0], [0, 2], [1, 4], [0, 4]], 1\n",
    "# gain_ratio_nominal(data_set,attr) == 0.06409559743967516\n",
    "\n",
    "def gain_ratio_numeric(data_set, attribute, steps):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data set, the index for a numeric attribute, and a step size for normalizing the data.\n",
    "    ========================================================================================================\n",
    "    Job:    Calculate the gain_ratio_numeric and find the best single threshold value\n",
    "            The threshold will be used to split examples into two sets\n",
    "                 those with attribute value GREATER THAN OR EQUAL TO threshold\n",
    "                 those with attribute value LESS THAN threshold\n",
    "            Use the equation here: https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "            And restrict your search for possible thresholds to examples with array index mod(step) == 0\n",
    "    ========================================================================================================\n",
    "    Output: This function returns the gain ratio and threshold value\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# data_set,attr,step = [[1,0.05], [1,0.17], [1,0.64], [0,0.38], [0,0.19], [1,0.68], [1,0.69], [1,0.17], [1,0.4], [0,0.53]], 1, 20\n",
    "# gain_ratio_numeric(data_set,attr,step) == (0.21744375685031775, 0.19)\n",
    "# data_set,attr,step = [[1, 0.35], [1, 0.24], [0, 0.67], [0, 0.36], [1, 0.94], [1, 0.4], [1, 0.15], [0, 0.1], [1, 0.61], [1, 0.17]], 1, 30\n",
    "# gain_ratio_numeric(data_set,attr,step) == (0.4125984252687806, 0.15)\n",
    "# data_set,attr,step = [[1, 0.1], [0, 0.29], [1, 0.03], [0, 0.47], [1, 0.25], [1, 0.12], [1, 0.67], [1, 0.73], [1, 0.85], [1, 0.25]], 1, 40\n",
    "# gain_ratio_numeric(data_set,attr,step) == (0.23645279766002802, 0.29)\n",
    "\n",
    "def split_on_nominal(data_set, attribute):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  subset of data set, the index for a nominal attribute.\n",
    "    ========================================================================================================\n",
    "    Job:    Creates a dictionary of all values of the attribute.\n",
    "    ========================================================================================================\n",
    "    Output: Dictionary of all values pointing to a list of all the data with that attribute\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# data_set, attr = [[0, 4], [1, 3], [1, 2], [0, 0], [0, 0], [0, 4], [1, 4], [0, 2], [1, 2], [0, 1]], 1\n",
    "# split_on_nominal(data_set, attr) == {0: [[0, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3]], 4: [[0, 4], [0, 4], [1, 4]]}\n",
    "# data_set, attr = [[1, 2], [1, 0], [0, 0], [1, 3], [0, 2], [0, 3], [0, 4], [0, 4], [1, 2], [0, 1]], 1\n",
    "# split on_nominal(data_set, attr) == {0: [[1, 0], [0, 0]], 1: [[0, 1]], 2: [[1, 2], [0, 2], [1, 2]], 3: [[1, 3], [0, 3]], 4: [[0, 4], [0, 4]]}\n",
    "\n",
    "def split_on_numerical(data_set, attribute, splitting_value):\n",
    "    '''\n",
    "    ========================================================================================================\n",
    "    Input:  Subset of data set, the index for a numeric attribute, threshold (splitting) value\n",
    "    ========================================================================================================\n",
    "    Job:    Categorizes data_set into a list that is greater than or equal to the splitting value, and lower.\n",
    "    ========================================================================================================\n",
    "    Output: Data less than splitting value and data that is equal to or greater than the splitting value\n",
    "    ========================================================================================================\n",
    "    '''\n",
    "    # Your code here\n",
    "    pass\n",
    "# ======== Test case =============================\n",
    "# d_set,a,sval = [[1, 0.25], [1, 0.89], [0, 0.93], [0, 0.48], [1, 0.19], [1, 0.49], [0, 0.6], [0, 0.6], [1, 0.34], [1, 0.19]],1,0.48\n",
    "# split_on_numerical(d_set,a,sval) == ([[1, 0.25], [1, 0.19], [1, 0.34], [1, 0.19]],[[1, 0.89], [0, 0.93], [0, 0.48], [1, 0.49], [0, 0.6], [0, 0.6]])\n",
    "# d_set,a,sval = [[0, 0.91], [0, 0.84], [1, 0.82], [1, 0.07], [0, 0.82],[0, 0.59], [0, 0.87], [0, 0.17], [1, 0.05], [1, 0.76]],1,0.17\n",
    "# split_on_numerical(d_set,a,sval) == ([[1, 0.07], [1, 0.05]],[[0, 0.91],[0, 0.84], [1, 0.82], [0, 0.82], [0, 0.59], [0, 0.87], [0, 0.17], [1, 0.76]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
